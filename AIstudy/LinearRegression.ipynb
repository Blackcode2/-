{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90e12779-61aa-42bd-8bac-796766d010e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0|     2.452|     0.376| 45.660004\n",
      "   10|     1.104|  0.003398|  0.206336\n",
      "   20|     1.013|  -0.02091|  0.001026\n",
      "   30|     1.007|  -0.02184|  0.000093\n",
      "   40|     1.006|  -0.02123|  0.000083\n",
      "   50|     1.006|  -0.02053|  0.000077\n",
      "   60|     1.005|  -0.01984|  0.000072\n",
      "   70|     1.005|  -0.01918|  0.000067\n",
      "   80|     1.005|  -0.01854|  0.000063\n",
      "   90|     1.005|  -0.01793|  0.000059\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = [1, 2, 3, 4, 5]   #[160, 170, 180]\n",
    "y = [1, 2, 3, 4, 5]  #[260, 270, 280]\n",
    "\n",
    "w = tf.Variable(2.9)\n",
    "b = tf.Variable(0.5)\n",
    "\n",
    "# hypothesis\n",
    "hypothesis = w * x + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "\n",
    "# learning_rate initialize\n",
    "learing_rate = 0.01\n",
    "\n",
    "for i in range(100):\n",
    "    #Gradient descent\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = w * x + b\n",
    "        loss = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "\n",
    "    w_grad, b_grad = tape.gradient(loss, [w, b])\n",
    "\n",
    "    w.assign_sub(learing_rate * w_grad)\n",
    "    b.assign_sub(learing_rate * b_grad)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(\"{:5}|{:10.4}|{:10.4}|{:10.6f}\".format(i, w.numpy(), b.numpy(), loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec886bb1-403f-49bd-9dda-d026d58ffefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10| 4505.8667| 24.338793\n",
      "   20|  947.7056| 12.063704\n",
      "   30|  199.4320|  6.434566\n",
      "   40|   42.0717|  3.853141\n",
      "   50|    8.9792|  2.669345\n",
      "   60|    2.0199|  2.126477\n",
      "   70|    0.5564|  1.877527\n",
      "   80|    0.2486|  1.763364\n",
      "   90|    0.1839|  1.711010\n",
      "  100|    0.1703|  1.687002\n",
      "  110|    0.1674|  1.675992\n",
      "  120|    0.1668|  1.670943\n",
      "  130|    0.1667|  1.668628\n",
      "  140|    0.1667|  1.667566\n",
      "  150|    0.1667|  1.667079\n",
      "  160|    0.1667|  1.666856\n",
      "  170|    0.1667|  1.666753\n",
      "  180|    0.1667|  1.666706\n",
      "  190|    0.1667|  1.666685\n",
      "  200|    0.1667|  1.666675\n",
      "  210|    0.1667|  1.666670\n",
      "  220|    0.1667|  1.666669\n",
      "  230|    0.1667|  1.666667\n",
      "  240|    0.1667|  1.666667\n",
      "  250|    0.1667|  1.666667\n",
      "  260|    0.1667|  1.666667\n",
      "  270|    0.1667|  1.666667\n",
      "  280|    0.1667|  1.666667\n",
      "  290|    0.1667|  1.666667\n"
     ]
    }
   ],
   "source": [
    "#Gradient descent with tensor flow\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "x = [1., 2., 3., 4.]\n",
    "y = [1., 3., 5., 7.]\n",
    "\n",
    "w = tf.Variable(tf.random.normal([1], -100., 100.))\n",
    "\n",
    "for step in range(1, 300):\n",
    "    hypothesis = w * x\n",
    "    loss = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "    \n",
    "    alpha = 0.01 #learning rate\n",
    "    gradient = tf.reduce_mean(tf.multiply(tf.multiply(w, x) - y, x))\n",
    "    descent = w - tf.multiply(alpha, gradient)\n",
    "    w.assign(descent)\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print(\"{:5}|{:10.4f}|{:10.6f}\".format(step, loss.numpy(), w.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52e54783-4f9e-46a8-9775-19804b2d179e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |    83.5000 |   4.750000\n",
      "   10 |    17.6915 |   3.080629\n",
      "   20 |     3.8521 |   2.315085\n",
      "   30 |     0.9417 |   1.964020\n",
      "   40 |     0.3297 |   1.803027\n",
      "   50 |     0.2009 |   1.729199\n",
      "   60 |     0.1739 |   1.695343\n",
      "   70 |     0.1682 |   1.679817\n",
      "   80 |     0.1670 |   1.672697\n",
      "   90 |     0.1667 |   1.669432\n",
      "  100 |     0.1667 |   1.667935\n",
      "  110 |     0.1667 |   1.667248\n",
      "  120 |     0.1667 |   1.666933\n",
      "  130 |     0.1667 |   1.666789\n",
      "  140 |     0.1667 |   1.666723\n",
      "  150 |     0.1667 |   1.666692\n",
      "  160 |     0.1667 |   1.666678\n",
      "  170 |     0.1667 |   1.666672\n",
      "  180 |     0.1667 |   1.666669\n",
      "  190 |     0.1667 |   1.666668\n",
      "  200 |     0.1667 |   1.666667\n",
      "  210 |     0.1667 |   1.666667\n",
      "  220 |     0.1667 |   1.666667\n",
      "  230 |     0.1667 |   1.666667\n",
      "  240 |     0.1667 |   1.666667\n",
      "  250 |     0.1667 |   1.666667\n",
      "  260 |     0.1667 |   1.666667\n",
      "  270 |     0.1667 |   1.666667\n",
      "  280 |     0.1667 |   1.666667\n",
      "  290 |     0.1667 |   1.666667\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "x_data = [1., 2., 3., 4.]\n",
    "y_data = [1., 3., 5., 7.]\n",
    "\n",
    "W = tf.Variable([5.0])\n",
    "\n",
    "for step in range(300):\n",
    "    hypothesis = W * x_data\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "    \n",
    "    alpha = 0.01  # learning rate\n",
    "    gradient = tf.reduce_mean(tf.multiply(tf.multiply(W, x_data) - y_data, x_data))\n",
    "    descent = W - tf.multiply(alpha, gradient)\n",
    "    W.assign(descent)\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print(\"{:5} | {:10.4f} | {:10.6f}\".format(step, cost.numpy(), W.numpy()[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
