{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff71e8a9-9377-49c4-a188-e876de90cade",
   "metadata": {},
   "source": [
    "개요: 럭키백의 확률  \n",
    "\n",
    "럭키백을 구입하면 랜덤한 확률로 다양한 생선 중 하나가 등장한다. 소비자는 이를 구입한 뒤 럭키백을 개봉해야 어떤 생선이 들어있는지 확인할 수 있다. 그리고, 판매자는 생선 별로 럭키백에 존재할 확률을 고지해준다. 이 확률을 알기 위해서는 어떤 모델을 활용해야 할까? k-최근접 이웃을 활용하여 럭키백의 생선 근처에 생선 별로 비율을 확인하면 될 듯 싶다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7adaa55-5ca8-4685-9797-2d1fae3b9a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diagonal</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bream</td>\n",
       "      <td>242.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bream</td>\n",
       "      <td>290.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bream</td>\n",
       "      <td>340.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bream</td>\n",
       "      <td>363.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bream</td>\n",
       "      <td>430.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Species  Weight  Length  Diagonal   Height   Width\n",
       "0   Bream   242.0    25.4      30.0  11.5200  4.0200\n",
       "1   Bream   290.0    26.3      31.2  12.4800  4.3056\n",
       "2   Bream   340.0    26.5      31.1  12.3778  4.6961\n",
       "3   Bream   363.0    29.0      33.5  12.7300  4.4555\n",
       "4   Bream   430.0    29.0      34.0  12.4440  5.1340"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fish = pd.read_csv('https://bit.ly/fish_csv')\n",
    "fish.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0967fd-b6d1-4eca-b719-78043d63d6e2",
   "metadata": {},
   "source": [
    "위 데이터프레임에서 Species는 타깃, 즉 물고기의 종류가 되고 나머지 weight, length, ... 등은 특성이 된다. 데이터를 뽑아 전처리하는 작업을 다음과 같이 거친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91078cd3-54a7-445c-8e53-9e248369e4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 프레임에서 여러 열을 선택하여 numpy 배열로 반환\n",
    "fish_input = fish[['Weight','Length','Diagonal','Height','Width']].to_numpy()\n",
    "fish_target = fish['Species'].to_numpy()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state=42)\n",
    "\n",
    "# 표준 정규화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c2270a7-c8fc-4667-83d2-0e9ee01b8c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8907563025210085\n",
      "0.85\n",
      "['Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish']\n",
      "['Perch' 'Smelt' 'Pike' 'Perch' 'Perch']\n",
      "[[0.     0.     1.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     1.     0.    ]\n",
      " [0.     0.     0.     1.     0.     0.     0.    ]\n",
      " [0.     0.     0.6667 0.     0.3333 0.     0.    ]\n",
      " [0.     0.     0.6667 0.     0.3333 0.     0.    ]]\n",
      "[['Roach' 'Perch' 'Perch']]\n"
     ]
    }
   ],
   "source": [
    "#이제 k-최근접 이웃 분류 클래스를 활용하여 실제 클래스(생선 종류)별 확률을 구해보자.\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kn = KNeighborsClassifier(n_neighbors=3)\n",
    "kn.fit(train_scaled,train_target)\n",
    "print(kn.score(train_scaled, train_target))\n",
    "print(kn.score(test_scaled, test_target))\n",
    "# 훈련 세트: 0.8907563025210085\n",
    "# 테스트 세트: 0.85\n",
    "\n",
    "\n",
    "print(kn.classes_) # 클래스 종류 출력(생선 종류)\n",
    "# ['Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish']\n",
    "\n",
    "print(kn.predict(test_scaled[:5])) # 처음 5개 테스트 샘플에 대한 클래스 예측 출력\n",
    "# ['Perch' 'Smelt' 'Pike' 'Perch' 'Perch']\n",
    "\n",
    "import numpy as np\n",
    "probability = kn.predict_proba(test_scaled[:5])\n",
    "print(np.round(probability, decimals=4))\n",
    "# 샘플 별 각 클래스 별 확률\n",
    "#['Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish']\n",
    "#[[0.     0.     1.     0.     0.     0.     0.    ]\n",
    "# [0.     0.     0.     0.     0.     1.     0.    ]\n",
    "# [0.     0.     0.     1.     0.     0.     0.    ]\n",
    "# [0.     0.     0.6667 0.     0.3333 0.     0.    ]\n",
    "# [0.     0.     0.6667 0.     0.3333 0.     0.    ]]\n",
    " \n",
    " \n",
    " # 시범삼아 네번째 샘플의 최근접 이웃 확인\n",
    "distances, indexes = kn.kneighbors(test_scaled[3:4])\n",
    "print(train_target[indexes])\n",
    "# [['Roach' 'Perch' 'Perch']]\n",
    "#Perch=2/3=0.6667, Roach=1/3=0.3333 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e54445-f5e0-44a8-aea5-28eef5713646",
   "metadata": {},
   "source": [
    "위는 그럴듯 하나 3개의 최근접 이웃만 활용하여 확률이 0, 1/3, 2/3 , 1로 매우 제한적이다.  \n",
    "  \n",
    "로지스틱 회귀를 이용한 이진 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "755ad9fb-a6a3-411c-857b-50070d51ad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bream' 'Smelt' 'Bream' 'Bream' 'Bream']\n",
      "['Bream' 'Smelt']\n",
      "[[0.99759855 0.00240145]\n",
      " [0.02735183 0.97264817]\n",
      " [0.99486072 0.00513928]\n",
      " [0.98584202 0.01415798]\n",
      " [0.99767269 0.00232731]]\n"
     ]
    }
   ],
   "source": [
    "# 도미와 빙어만 추출한 훈련 세트 추출\n",
    "bream_smelt_indexes = (train_target == 'Bream') | (train_target == 'Smelt')\n",
    "train_bream_smelt = train_scaled[bream_smelt_indexes]\n",
    "target_bream_smelt = train_target[bream_smelt_indexes]\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_bream_smelt,target_bream_smelt)\n",
    "\n",
    "\n",
    "# 처음 5개 샘플의 분류\n",
    "print(lr.predict(train_bream_smelt[:5]))\n",
    "#결과:['Bream' 'Smelt' 'Bream' 'Bream' 'Bream']\n",
    "\n",
    "\n",
    "# 처음 5개 샘플의 클래스별 확률\n",
    "print(lr.classes_)\n",
    "print(lr.predict_proba(train_bream_smelt[:5]))\n",
    "\n",
    "# 결과\n",
    "#['Bream' 'Smelt']\n",
    "#[[0.99759855 0.00240145]\n",
    " #[0.02735183 0.97264817]\n",
    " #[0.99486072 0.00513928]\n",
    " #[0.98584202 0.01415798]\n",
    " #[0.99767269 0.00232731]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e599e56-6f1c-4456-8411-e1e586d8208a",
   "metadata": {},
   "source": [
    "로지스틱 회귀를 이용한 다중 분류  \n",
    "\n",
    "다음으로 최종 목표로 했던 다중 분류를 로지스틱 회귀로 수행해보자. 로지스틱 회귀 또한 릿지 회귀와 비슷하게 계수의 제곱을 규제하여 과대적합/과소적합을 조절한다. 로지스틱 회귀에서는 alpha 대신 C 값으로 이를 규제한다. 다만, 로지스틱 회귀에서는 C가 커질수록 큐제가 적어진다는 점이 반대이다. 또한, Logistic Regression 클래스는 반복적인 알고리즘을 활용하는데 이 때 max_iter 매개 변수를 통해 반복 횟수를 지정할 수 있다. 반복 횟수가 늘어날 수록 모델을 충분히 훈련시킬 수 있게 된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcc66b5b-91af-48cf-8b1f-bca13d73cfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9327731092436975\n",
      "0.925\n",
      "['Perch' 'Smelt' 'Pike' 'Roach' 'Perch']\n",
      "['Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish']\n",
      "[[0.    0.014 0.841 0.    0.136 0.007 0.003]\n",
      " [0.    0.003 0.044 0.    0.007 0.946 0.   ]\n",
      " [0.    0.    0.034 0.935 0.015 0.016 0.   ]\n",
      " [0.011 0.034 0.306 0.007 0.567 0.    0.076]\n",
      " [0.    0.    0.904 0.002 0.089 0.002 0.001]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=20, max_iter=1000)\n",
    "lr.fit(train_scaled, train_target)\n",
    "print(lr.score(train_scaled,train_target))\n",
    "print(lr.score(test_scaled,test_target))\n",
    "#훈련 세트:0.9327731092436975\n",
    "#테스트 세트:0.925\n",
    "\n",
    "print(lr.predict(test_scaled[:5]))\n",
    "#['Perch' 'Smelt' 'Pike' 'Roach' 'Perch']\n",
    "\n",
    "print(lr.classes_)\n",
    "print(np.round(lr.predict_proba(test_scaled[:5]),decimals=3))\n",
    "#['Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish']\n",
    "#[[0.    0.014 0.841 0.    0.136 0.007 0.003]\n",
    " #[0.    0.003 0.044 0.    0.007 0.946 0.   ]\n",
    " #[0.    0.    0.034 0.935 0.015 0.016 0.   ]\n",
    " #[0.011 0.034 0.306 0.007 0.567 0.    0.076]\n",
    " #[0.    0.    0.904 0.002 0.089 0.002 0.001]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed740a58-8531-4ac7-9469-6e37301d0b3e",
   "metadata": {},
   "source": [
    "위를 통해 로지스틱 회귀를 활용하여 다중 분류를 하는 방법은 알게 되었다. 실제 다중 분류의 선형 방정식은 어떤 형태인지 알아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70298122-ec90-4f23-8f8e-fd42750dae62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 5) (7,)\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_.shape,lr.intercept_.shape)\n",
    "#결과: (7, 5) (7,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca3c4d5-b7d3-4cdb-951b-dc55ea65abae",
   "metadata": {},
   "source": [
    "위 데이터에서는 'Weight','Length','Diagonal','Height','Width' 5개의 특성을 활용하여 coef_ 배열의 열은 5개이다. 그런데 coef_, intercept_의 행이 모두 7개이다. 이는 클래스마다 z값을 하나씩 계산한다는 점을 의미한다. 생선의 종류가 7개이므로 7개 각각에 대하여 계산한 뒤 가장 높은 z값을 가진 클래스가 예측 클래스가 된다. 이진 분류에서는 시그모이드 함수를 활용하여 0~1 사이의 값으로 치환했으나, 다중 분류의 경우 소프트맥스 함수를 활용하여 7개의 z값을 확률로 변환시켜 총 합이 1이 되게 한다.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de312f31-e72f-4d8a-adf6-c2ea1f500031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -6.5    1.03   5.16  -2.73   3.34   0.33  -0.63]\n",
      " [-10.86   1.93   4.77  -2.4    2.98   7.84  -4.26]\n",
      " [ -4.34  -6.23   3.17   6.49   2.36   2.42  -3.87]\n",
      " [ -0.68   0.45   2.65  -1.19   3.26  -5.75   1.26]\n",
      " [ -6.4   -1.99   5.82  -0.11   3.5   -0.11  -0.71]]\n",
      "[[0.    0.014 0.841 0.    0.136 0.007 0.003]\n",
      " [0.    0.003 0.044 0.    0.007 0.946 0.   ]\n",
      " [0.    0.    0.034 0.935 0.015 0.016 0.   ]\n",
      " [0.011 0.034 0.306 0.007 0.567 0.    0.076]\n",
      " [0.    0.    0.904 0.002 0.089 0.002 0.001]]\n"
     ]
    }
   ],
   "source": [
    "#소프트맥스 함수\n",
    "\n",
    "decision = lr.decision_function(test_scaled[:5])\n",
    "print(np.round(decision,decimals=2))\n",
    "\n",
    "from scipy.special import softmax\n",
    "print(np.round(softmax(decision,axis=1),decimals=3))\n",
    "\n",
    "# 5개의 샘플 데이터에 대한 클래스 별 z값\n",
    "#[[ -6.5    1.03   5.16  -2.73   3.34   0.33  -0.63]\n",
    " #[-10.86   1.93   4.77  -2.4    2.98   7.84  -4.26]\n",
    " #[ -4.34  -6.23   3.17   6.49   2.36   2.42  -3.87]\n",
    " #[ -0.68   0.45   2.65  -1.19   3.26  -5.75   1.26]\n",
    " #[ -6.4   -1.99   5.82  -0.11   3.5   -0.11  -0.71]]\n",
    " \n",
    "# 위 값들에 대해 소프트맥스 함수를 거쳐 나타낸 5개 샘플의 각 클래스별 확률\n",
    "#[[0.    0.014 0.841 0.    0.136 0.007 0.003]\n",
    " #[0.    0.003 0.044 0.    0.007 0.946 0.   ]\n",
    " #[0.    0.    0.034 0.935 0.015 0.016 0.   ]\n",
    " #[0.011 0.034 0.306 0.007 0.567 0.    0.076]\n",
    " #[0.    0.    0.904 0.002 0.089 0.002 0.001]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
